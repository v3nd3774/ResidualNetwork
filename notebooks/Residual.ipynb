{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import random\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "common_kwargs_set = {\n",
    "    \"root\":os.path.abspath('.').split(os.path.sep)[0]+os.path.sep+\"cifardata\",\n",
    "    \"transform\":transform,\n",
    "    \"download\":True}\n",
    "common_kwargs_loader = {\"batch_size\":128,\n",
    "                        \"num_workers\":4}\n",
    "trainset = torchvision.datasets.CIFAR10(train=True, **common_kwargs_set)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, **common_kwargs_loader)   \n",
    "import pdb \n",
    "def push_to_gpu(dataloader):\n",
    "    data = []\n",
    "    for data_batch in dataloader:\n",
    "        images = data_batch[0].to(\"cuda\", non_blocking=True)\n",
    "        labels = data_batch[1].to(\"cuda\", non_blocking=True)\n",
    "        data.append((images, labels))\n",
    "    return data\n",
    "\n",
    "holdoutset = torchvision.datasets.CIFAR10(train=False, **common_kwargs_set)\n",
    "holdoutloader = torch.utils.data.DataLoader(holdoutset, **common_kwargs_loader)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    trainloader = push_to_gpu(trainloader)\n",
    "    holdoutloader = push_to_gpu(holdoutloader) \n",
    "\n",
    "# in the holdoutloader the last batch of 16 examples breaks the network since the 16 examples are different\n",
    "# from what the network has been fed before (batches of size 128), so add elements from the first batch\n",
    "needy_batch = holdoutloader[-1]\n",
    "need_examples = common_kwargs_loader[\"batch_size\"] - len(needy_batch[0])\n",
    "if need_examples > 0:\n",
    "    images = holdoutloader[0][0][:need_examples]\n",
    "    labels = holdoutloader[0][1][:need_examples]\n",
    "    new_image_batch = torch.cat((needy_batch[0], images), 0)\n",
    "    new_label_batch = torch.cat((needy_batch[1], labels), 0)\n",
    "    new_needy_batch = (new_image_batch, new_label_batch)\n",
    "    holdoutloader[-1] = new_needy_batch\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cuda avail: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images[:4], labels[:4]\n",
    "print(\" \".join(\"%5s\" % classes[labels[j]] for j in range(4)))\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from boilerplate import Net, ResNet, evaluate_network_opt\n",
    "perf_nonrnn, nonrnn = evaluate_network_opt(\n",
    "    trainloader, holdoutloader, Net, common_kwargs_loader[\"batch_size\"], step_size=480,epochs_desired=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_rnn, rnn = evaluate_network_opt(\n",
    "    trainloader, holdoutloader, ResNet, common_kwargs_loader[\"batch_size\"], step_size=480,epochs_desired=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered = [list(filter(lambda x: x[1], perf_nonrnn.items())),\n",
    "            list(filter(lambda x: x[1], perf_rnn.items()))]\n",
    "import matplotlib.colors as colors\n",
    "import random\n",
    "random_colors = enumerate(random.sample(colors.get_named_colors_mapping().keys(), 10))\n",
    "from matplotlib.pyplot import figure\n",
    "def set_figsize(plots):\n",
    "    fig, axs = plt.subplots(plots, 1, constrained_layout=True)\n",
    "    fig.set_size_inches(11*plots, 8.5*plots)\n",
    "    fig.dpi=80\n",
    "    fig.facecolor=\"w\"\n",
    "    fig.edgecolor=\"k\"\n",
    "    return fig, axs\n",
    "fig, axs = set_figsize(2)\n",
    "axs = [axs]\n",
    "for idx, title in enumerate([\n",
    "    \"Unmodified NN\", \n",
    "    \"RNN (Custom Impl)\"], 0):\n",
    "    axs[idx].set_title(title)\n",
    "for idx in range(2):\n",
    "    axs[idx].set_xlabel(f\"No. of {trainloader.batch_size} sample batches trained on\")\n",
    "    axs[idx].set_ylabel(f\"AUC on holdout data\")\n",
    "colors = {idx:c for idx, c in random_colors}\n",
    "for label in range(0, 10):\n",
    "    for idx in range(2):\n",
    "        axs[idx].plot(list(map(lambda d: d[0], filtered[idx])), # x\n",
    "                      list(map(lambda d: d[1][label], filtered[idx])), # auc for label\n",
    "                      colors[label],\n",
    "                      label=classes[label])\n",
    "for idx in range(2):\n",
    "    axs[idx].legend()\n",
    "fig.savefig(\"C:\\\\Users\\\\v3nd3774\\\\.babun\\\\cygwin\\\\home\\\\v3nd3774\\\\ResidualNetwork\\\\comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(), \"C:\\\\Users\\\\v3nd3774\\\\.babun\\\\cygwin\\\\home\\\\v3nd3774\\\\ResidualNetwork\\\\rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"C:\\\\Users\\\\v3nd3774\\\\.babun\\\\cygwin\\\\home\\\\v3nd3774\\\\ResidualNetwork\\\\rnn_perf.dict\", \"wb\") as f:\n",
    "    pickle.dump(perf_rnn, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
